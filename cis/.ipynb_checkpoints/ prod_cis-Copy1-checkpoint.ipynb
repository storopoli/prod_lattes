{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     http://lattes.cnpq.br/3410710553298468\n",
       "1     http://lattes.cnpq.br/2503278782954156\n",
       "2     http://lattes.cnpq.br/9619504618003187\n",
       "3     http://lattes.cnpq.br/9287861770521337\n",
       "4     http://lattes.cnpq.br/2098643827162361\n",
       "5     http://lattes.cnpq.br/6214289236131303\n",
       "6     http://lattes.cnpq.br/8140882954837573\n",
       "7     http://lattes.cnpq.br/7933402277545891\n",
       "8     http://lattes.cnpq.br/2281909649311607\n",
       "9     http://lattes.cnpq.br/2089341893296080\n",
       "10    http://lattes.cnpq.br/0969838199511588\n",
       "11    http://lattes.cnpq.br/2145753478351346\n",
       "12    http://lattes.cnpq.br/5664558410139621\n",
       "13    http://lattes.cnpq.br/9164867295710218\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importar lista e lattes do arquivo qualis baixado do Sucupira (XLS)\n",
    "qualis = pd.read_table('classificacoes_publicadas_planejamento_urbano_e_regional_demografia_2017_1496941695959.xls',\n",
    "                       encoding='latin_1')   \n",
    "list_lattes = list_lattes[0]\n",
    "list_lattes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "for row in list_lattes:\n",
    "    url = row\n",
    "    page = requests.get(url)\n",
    "    #Parse o HTML\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    #Achar nome do titular do CV Lattes\n",
    "    name = soup.find(class_='nome')\n",
    "    name = name.text\n",
    "    #Achar todos os artigos completos publicados em periodicos\n",
    "    tb = soup.find_all('div', class_='artigo-completo')  \n",
    "    #fazer uma lista com cada um dos artigos completos\n",
    "    prod = []\n",
    "    for i in tb:\n",
    "        prod.append(i.text)\n",
    "        #split da lista\n",
    "        _ = [i.split('\\s\\d{1,2}\\.\\s', 1)[0] for i in prod]\n",
    "        #remover duplicados de cada artigo\n",
    "        prod = [re.sub('\\n\\d{1,2}\\.', '', i) for i in prod]\n",
    "        prod = [re.sub('\\n', '', i) for i in prod]\n",
    "        prod = [re.sub('.*\\.\\d{4}', '',i) for i in prod]\n",
    "        prod = [re.sub('\\d{1,2}\\w*\\,\\s\\w*\\B\\d{4}', '',i) for i in prod]\n",
    "        prod = [re.sub('\\d{1,2}\\w{2,}\\s\\w{2,}\\d{4}', '',i) for i in prod]\n",
    "        prod = [re.sub('\\w{2,}\\s\\w{2,}\\,\\s[\\wÀ-ú]*\\d{4}', '',i) for i in prod]\n",
    "        prod = [re.sub('\\w{2,}\\,\\s[\\wÀ-ú]*\\s[\\wÀ-ú]*\\d{4}', '',i) for i in prod]\n",
    "        #duplicar o nome para o tamanho da lista dos artigos publicados\n",
    "    name_list = [name] * len(prod)\n",
    "    new_df = pd.DataFrame({'Nome': name_list, 'ArtigosCompletos':prod})\n",
    "    temp_df = temp_df.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegar o ano da citação\n",
    "temp_df['Ano'] = \"\"\n",
    "temp_df['Ano'] = temp_df.ArtigosCompletos.str[-6:-2]\n",
    "temp_df.Ano = temp_df.Ano.str.extract(r'(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar df do qualis dos periodicos da area\n",
    "#nao modificar o nome do xls baixado do Sucupira\n",
    "#abrir o arquivo no excel em Windows e salvar como .xlsx\n",
    "qualis = pd.read_excel('classificacoes_publicadas_planejamento_urbano_e_regional_demografia_2017_1496941695959.xls.xlsx')\n",
    "temp_df['periodicos'] = \"\"\n",
    "L1 = temp_df.ArtigosCompletos\n",
    "L2 = qualis.Título\n",
    "#se atentar ao terceiro argumento da get_close_matches que eh o cutoff\n",
    "temp_df['periodicos'] = [difflib.get_close_matches(i, L2, 1, 0.01)[0] for i in L1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegar o qualis respectivo de cara periodico da area\n",
    "temp_df = temp_df.merge(qualis, left_on='periodicos', right_on='Título')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar um dicionario para computar a pontuação \n",
    "pontuacao={\n",
    "    'A1':100,\n",
    "    'A2':85,\n",
    "    'B1':70,\n",
    "    'B2':50,\n",
    "    'B3':40,\n",
    "    'B4':20,\n",
    "    'B5':10\n",
    "}\n",
    "temp_df['pontuacao'] = temp_df.Estrato.apply(lambda x: pontuacao.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranjando as colunas do df\n",
    "temp_df = temp_df[['Nome', 'Ano', 'ArtigosCompletos', 'Título', 'ISSN', 'Estrato', 'pontuacao']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_excel('prod_cis.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
